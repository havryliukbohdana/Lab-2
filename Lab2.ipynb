{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRmwDHZmQZHtSDzNZNca9X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Ğ’ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ÑÑ”Ğ¼Ğ¾ Ğ½ĞµĞ¾Ğ±Ñ…Ñ–Ğ´Ğ½Ñ– Ğ±Ñ–Ğ±Ğ»Ñ–Ğ¾Ñ‚ĞµĞºĞ¸\n",
        "!pip install ultralytics torchinfo pandas roboflow -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VwtN4qWXega",
        "outputId": "d86661c5-b8c1-404c-8db1-0ed8a173c4f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/89.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ğ†Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ÑƒÑ”Ğ¼Ğ¾ Ğ¿Ğ°ĞºĞµÑ‚Ğ¸\n",
        "import torch\n",
        "import os\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from torchinfo import summary\n",
        "from google.colab import files\n",
        "from roboflow import Roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUs_PMkdXgPN",
        "outputId": "e2a49a1f-18e9-4d88-b992-e49bd2a41668"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ° GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ñ‚ÑŒÑÑ Ğ¿Ñ€Ğ¸ÑÑ‚Ñ€Ñ–Ğ¹: {device}\")\n",
        "if device.type == 'cpu':\n",
        "    print(\"GPU Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59WSWaV6XirK",
        "outputId": "7c5cbfc4-6baa-4ae4-ff0f-09b20635a3c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ñ‚ÑŒÑÑ Ğ¿Ñ€Ğ¸ÑÑ‚Ñ€Ñ–Ğ¹: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "src8ozmXXZ9n",
        "outputId": "371b003b-dbea-4ea9-e6fb-e7d128cd4bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ”ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñƒ\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in bdd100k_daytime-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114804/114804 [00:02<00:00, 45992.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to bdd100k_daytime-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2612/2612 [00:00<00:00, 5459.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ğ”ĞµĞ½Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–: /content/bdd100k_daytime-1\n",
            "\n",
            "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ ĞÑ–Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñƒ\n",
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rloading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in bdd100k-finetune-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1459607/1459607 [00:28<00:00, 51238.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to bdd100k-finetune-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63810/63810 [00:12<00:00, 5094.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ĞÑ–Ñ‡Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–: /content/bdd100k-finetune-1\n"
          ]
        }
      ],
      "source": [
        "RF_API_KEY = \"cPFHreBTk8PuDYeI6HyZ\"\n",
        "\n",
        "rf = Roboflow(api_key=RF_API_KEY)\n",
        "\n",
        "# 1. Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ”Ğ¼Ğ¾ Ğ”Ğ•ĞĞĞ˜Ğ™ Ğ½Ğ°Ğ±Ñ–Ñ€\n",
        "print(\"Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ”ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñƒ\")\n",
        "project_day = rf.workspace(\"bohdana\").project(\"bdd100k_daytime-u8j82-c4nyg\")\n",
        "version_day = project_day.version(1)\n",
        "dataset_day = version_day.download(\"yolov8\")\n",
        "DAY_DATA_PATH = dataset_day.location\n",
        "print(f\"Ğ”ĞµĞ½Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–: {DAY_DATA_PATH}\")\n",
        "\n",
        "# 2. Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ”Ğ¼Ğ¾ ĞĞ†Ğ§ĞĞ˜Ğ™ Ğ½Ğ°Ğ±Ñ–Ñ€\n",
        "print(\"\\nĞ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ ĞÑ–Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñƒ\")\n",
        "project_night = rf.workspace(\"bohdana\").project(\"bdd100k-finetune-e2bk1\")\n",
        "version_night = project_night.version(1)\n",
        "dataset_night = version_night.download(\"yolov8\")\n",
        "NIGHT_DATA_PATH = dataset_night.location\n",
        "print(f\"ĞÑ–Ñ‡Ğ½Ñ– Ğ´Ğ°Ğ½Ñ–: {NIGHT_DATA_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Ğ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ğ¹Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ .yaml Ğ´Ğ»Ñ Domain Shift\n",
        "print(\"\\nĞ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ bdd_domain_shift.yaml\")\n",
        "\n",
        "# ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ ĞºĞ»Ğ°ÑĞ¸ Ğ· Ğ´ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñƒ\n",
        "with open(f'{DAY_DATA_PATH}/data.yaml', 'r') as f:\n",
        "    day_yaml = yaml.safe_load(f)\n",
        "    class_names = day_yaml['names']\n",
        "    num_classes = day_yaml['nc']\n",
        "\n",
        "# ĞšĞ¾Ğ½Ñ„Ñ–Ğ³: Ğ¢Ñ€ĞµĞ½ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ½Ğ° Ğ´Ğ½Ñ–, Ğ¢ĞµÑÑ‚ Ğ½Ğ° Ğ½Ğ¾Ñ‡Ñ–\n",
        "domain_shift_config = {\n",
        "    'train': f'{DAY_DATA_PATH}/train/images',\n",
        "    'val': f'{DAY_DATA_PATH}/valid/images',\n",
        "    'test': f'{NIGHT_DATA_PATH}/test/images', # Ğ¢ĞµÑÑ‚ÑƒÑ”Ğ¼Ğ¾ Ğ½Ğ° Ğ½Ñ–Ñ‡Ğ½Ğ¸Ñ…!\n",
        "    'nc': num_classes,\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "with open('bdd_domain_shift.yaml', 'w') as f:\n",
        "    yaml.dump(domain_shift_config, f)\n",
        "\n",
        "print(\"Ğ¤Ğ°Ğ¹Ğ» ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ— ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¾.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNTQ2uVtc_Zx",
        "outputId": "429a3b20-fde0-4f88-a328-f47e534f4fc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ğ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ bdd_domain_shift.yaml\n",
            "Ğ¤Ğ°Ğ¹Ğ» ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ— ÑÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ¾.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ğ¤ÑƒĞ½ĞºÑ†Ñ–Ñ Ğ´Ğ»Ñ Ñ‡Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ yaml Ñ„Ğ°Ğ¹Ğ»Ñƒ\n",
        "def get_classes_from_yaml(path):\n",
        "    with open(path, 'r') as f:\n",
        "        data = yaml.safe_load(f)\n",
        "        return data['names'], data['nc']\n",
        "\n",
        "# ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ Ñ–Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ñ–Ñ Ğ· Ğ¾Ğ±Ğ¾Ñ… Ğ½Ğ°Ğ±Ğ¾Ñ€Ñ–Ğ²\n",
        "try:\n",
        "    day_names, day_nc = get_classes_from_yaml(f'{DAY_DATA_PATH}/data.yaml')\n",
        "    night_names, night_nc = get_classes_from_yaml(f'{NIGHT_DATA_PATH}/data.yaml')\n",
        "\n",
        "    print(f\"Ğ”ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€: {day_nc} ĞºĞ»Ğ°ÑÑ–Ğ² -> {day_names}\")\n",
        "    print(f\"ĞÑ–Ñ‡Ğ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€: {night_nc} ĞºĞ»Ğ°ÑÑ–Ğ² -> {night_names}\")\n",
        "\n",
        "    # Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ ĞºĞ»Ğ°ÑĞ¸ Ğ· ĞĞ†Ğ§ĞĞĞ“Ğ Ğ½Ğ°Ğ±Ğ¾Ñ€Ñƒ, ÑĞºÑ‰Ğ¾ Ñ‚Ğ°Ğ¼ Ñ—Ñ… Ğ±Ñ–Ğ»ÑŒÑˆĞµ, Ñ‰Ğ¾Ğ± ÑƒĞ½Ğ¸ĞºĞ½ÑƒÑ‚Ğ¸ Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ¸ \"index out of range\".\n",
        "\n",
        "    target_names = night_names\n",
        "    target_nc = night_nc\n",
        "\n",
        "    print(f\"\\nĞ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ: {target_nc} ĞºĞ»Ğ°ÑÑ–Ğ².\")\n",
        "\n",
        "    # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ Ğ½Ğ°Ñˆ ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ Ğ´Ğ»Ñ Domain Shift\n",
        "    domain_shift_config = {\n",
        "        'train': f'{DAY_DATA_PATH}/train/images',\n",
        "        'val': f'{DAY_DATA_PATH}/valid/images',\n",
        "        'test': f'{NIGHT_DATA_PATH}/test/images',\n",
        "\n",
        "        'nc': target_nc,\n",
        "        'names': target_names\n",
        "    }\n",
        "\n",
        "    with open('bdd_domain_shift.yaml', 'w') as f:\n",
        "        yaml.dump(domain_shift_config, f)\n",
        "\n",
        "    print(\"Ğ¤Ğ°Ğ¹Ğ» bdd_domain_shift.yaml ÑƒÑĞ¿Ñ–ÑˆĞ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‡Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ– YAML: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5AG65nxf-mD",
        "outputId": "d40b7307-9685-4582-9ed2-e90d877740cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ğ”ĞµĞ½Ğ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€: 7 ĞºĞ»Ğ°ÑÑ–Ğ² -> ['bus', 'car', 'person', 'rider', 'traffic light', 'traffic sign', 'truck']\n",
            "ĞÑ–Ñ‡Ğ½Ğ¸Ğ¹ Ğ½Ğ°Ğ±Ñ–Ñ€: 22 ĞºĞ»Ğ°ÑÑ–Ğ² -> ['1', '10', '2', '3', '4', '5', '6', '7', '8', '9', 'bike', 'bus', 'car', 'motor', 'person', 'rider', 'tl_green', 'tl_none', 'tl_red', 'tl_yellow', 'train', 'truck']\n",
            "\n",
            "Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ: 22 ĞºĞ»Ğ°ÑÑ–Ğ².\n",
            "Ğ¤Ğ°Ğ¹Ğ» bdd_domain_shift.yaml ÑƒÑĞ¿Ñ–ÑˆĞ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¾!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm {NIGHT_DATA_PATH}/test/labels.cache\n",
        "!rm {DAY_DATA_PATH}/train/labels.cache\n",
        "!rm {DAY_DATA_PATH}/valid/labels.cache"
      ],
      "metadata": {
        "id": "sSIqZakmh5wN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfe44a4-5261-4be3-8433-406ab85075f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/bdd100k-finetune-1/test/labels.cache': No such file or directory\n",
            "rm: cannot remove '/content/bdd100k_daytime-1/train/labels.cache': No such file or directory\n",
            "rm: cannot remove '/content/bdd100k_daytime-1/valid/labels.cache': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8n (Nano)\n",
        "# ĞĞ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ (Train on Day)\n",
        "print(\"ĞŸĞ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ğ½Ğ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ YOLOv8n\")\n",
        "!yolo task=detect mode=train \\\n",
        "    model=yolov8n.pt \\\n",
        "    data=bdd_domain_shift.yaml \\\n",
        "    epochs=20 \\\n",
        "    imgsz=640 \\\n",
        "    project='BDD_DomainShift_Lab' \\\n",
        "    name='yolov8n_day_train' \\\n",
        "    seed=42 \\\n",
        "    exist_ok=True \\\n",
        "    verbose=False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7V_w_5JYOWM",
        "outputId": "c3baf6c6-b7a3-4b0b-9f91-8287bdeb712c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ĞŸĞ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ğ½Ğ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ YOLOv8n\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 94.1MB/s 0.1s\n",
            "Ultralytics 8.3.236 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=bdd_domain_shift.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_day_train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=BDD_DomainShift_Lab, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/BDD_DomainShift_Lab/yolov8n_day_train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 21.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    755602  ultralytics.nn.modules.head.Detect           [22, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,015,138 parameters, 3,015,122 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 82.6MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2347.5Â±971.7 MB/s, size: 86.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/bdd100k_daytime-1/train/labels... 1000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1000/1000 2.1Kit/s 0.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/bdd100k_daytime-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1099.1Â±556.0 MB/s, size: 89.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/bdd100k_daytime-1/valid/labels... 200 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 200/200 1.5Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/bdd100k_daytime-1/valid/labels.cache\n",
            "Plotting labels to /content/BDD_DomainShift_Lab/yolov8n_day_train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/BDD_DomainShift_Lab/yolov8n_day_train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      2.77G      1.609      3.464      1.069        269        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.8it/s 22.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.3it/s 3.0s\n",
            "                   all        200       3996     0.0483      0.196     0.0933     0.0608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20       2.8G       1.53      1.774      1.046        211        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.5it/s 17.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.8it/s 2.5s\n",
            "                   all        200       3996      0.524      0.226      0.206      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      3.08G      1.494      1.441      1.034        322        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.3s\n",
            "                   all        200       3996      0.555      0.243      0.243      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20       3.4G      1.455      1.312       1.03        312        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.6it/s 17.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.6it/s 2.6s\n",
            "                   all        200       3996      0.555       0.25      0.269      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      3.42G      1.436      1.229      1.018        193        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.6it/s 2.7s\n",
            "                   all        200       3996      0.406      0.297      0.293      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      3.74G       1.41      1.183      1.013        259        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.6it/s 17.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.1it/s 2.3s\n",
            "                   all        200       3996      0.437      0.309      0.305      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20      3.76G      1.396      1.158      1.004        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.4it/s 18.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.3it/s 3.0s\n",
            "                   all        200       3996      0.411      0.313      0.305      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20      3.78G      1.394      1.148      1.004        302        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.7it/s 17.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s\n",
            "                   all        200       3996      0.587      0.304      0.312       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20       3.8G      1.375      1.121      1.005        145        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.6it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.6it/s 2.6s\n",
            "                   all        200       3996       0.39      0.333      0.315      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      3.81G       1.36      1.086     0.9954        248        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.2it/s 2.2s\n",
            "                   all        200       3996      0.585      0.312      0.322      0.189\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      3.83G      1.389      1.209      1.002        148        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.1it/s 2.3s\n",
            "                   all        200       3996      0.471      0.303      0.327      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      3.85G      1.366      1.123     0.9907         85        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 4.0it/s 15.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.5it/s 2.0s\n",
            "                   all        200       3996      0.436      0.339      0.333      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20      3.87G      1.365      1.101     0.9875        153        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.3s\n",
            "                   all        200       3996      0.455      0.315      0.338        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      3.87G       1.35      1.072     0.9862        150        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 4.0it/s 15.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.3s\n",
            "                   all        200       3996      0.445      0.323      0.343      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20       3.9G      1.342      1.052     0.9785        108        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.7it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s\n",
            "                   all        200       3996      0.441      0.334      0.342      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      3.92G      1.339      1.055     0.9784        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.9it/s 16.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.1it/s 2.3s\n",
            "                   all        200       3996      0.421      0.355      0.345      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      3.93G      1.331      1.034     0.9734        174        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.7it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.1it/s 2.3s\n",
            "                   all        200       3996      0.444      0.335       0.35      0.202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      3.94G      1.317      1.026     0.9744         98        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.9it/s 16.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.8it/s 2.5s\n",
            "                   all        200       3996      0.461      0.331      0.353      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      3.97G      1.319      1.018     0.9725        168        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.5it/s 18.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.2it/s 2.2s\n",
            "                   all        200       3996      0.452      0.342      0.358      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      3.98G      1.318      1.014       0.97        138        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 4.0it/s 15.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.8it/s 2.5s\n",
            "                   all        200       3996      0.466      0.328      0.356       0.21\n",
            "\n",
            "20 epochs completed in 0.112 hours.\n",
            "Optimizer stripped from /content/BDD_DomainShift_Lab/yolov8n_day_train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/BDD_DomainShift_Lab/yolov8n_day_train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/BDD_DomainShift_Lab/yolov8n_day_train/weights/best.pt...\n",
            "Ultralytics 8.3.236 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,009,938 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 1.7it/s 4.0s\n",
            "                   all        200       3996      0.451      0.342      0.357      0.212\n",
            "Speed: 0.3ms preprocess, 2.4ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/BDD_DomainShift_Lab/yolov8n_day_train\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8s (Small)\n",
        "# ĞĞ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ (Train on Day)\n",
        "print(\"ĞŸĞ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ğ½Ğ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ YOLOv8s\")\n",
        "!yolo task=detect mode=train \\\n",
        "    model=yolov8s.pt \\\n",
        "    data=bdd_domain_shift.yaml \\\n",
        "    epochs=20 \\\n",
        "    imgsz=640 \\\n",
        "    project='BDD_DomainShift_Lab' \\\n",
        "    name='yolov8s_day_train' \\\n",
        "    seed=42 \\\n",
        "    exist_ok=True \\\n",
        "    verbose=False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiVT87vKdiDM",
        "outputId": "095746ec-ba33-4494-8782-e14fcc5cde7b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ĞŸĞ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº Ğ½Ğ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ YOLOv8s\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 21.5MB 184.2MB/s 0.1s\n",
            "Ultralytics 8.3.236 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=bdd_domain_shift.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s_day_train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=BDD_DomainShift_Lab, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/BDD_DomainShift_Lab/yolov8s_day_train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2124562  ultralytics.nn.modules.head.Detect           [22, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,144,114 parameters, 11,144,098 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2502.4Â±1005.3 MB/s, size: 86.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/bdd100k_daytime-1/train/labels.cache... 1000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1000/1000 17.6Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1746.1Â±1044.8 MB/s, size: 89.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/bdd100k_daytime-1/valid/labels.cache... 200 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 200/200 1.4Mit/s 0.0s\n",
            "Plotting labels to /content/BDD_DomainShift_Lab/yolov8s_day_train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/BDD_DomainShift_Lab/yolov8s_day_train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      4.01G      1.434      2.155      1.055        269        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.8it/s 22.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.1it/s 2.3s\n",
            "                   all        200       3996      0.603      0.328       0.35      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      4.05G      1.307      1.059     0.9958        211        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.2it/s 1.7s\n",
            "                   all        200       3996      0.544      0.389      0.394      0.229\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      4.32G      1.314      1.001     0.9959        322        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.1it/s 1.7s\n",
            "                   all        200       3996      0.478      0.402      0.399      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20      4.66G      1.276     0.9294     0.9857        312        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.3s\n",
            "                   all        200       3996       0.58      0.387      0.419      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      4.69G      1.281     0.8914     0.9842        193        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.3it/s 1.6s\n",
            "                   all        200       3996      0.583      0.424      0.438      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20         5G      1.255     0.8601     0.9757        259        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 20.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.4it/s 1.6s\n",
            "                   all        200       3996      0.556      0.431      0.447      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20         5G      1.242     0.8402     0.9672        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.9it/s 1.8s\n",
            "                   all        200       3996      0.564      0.415      0.443      0.266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20         5G      1.237     0.8335     0.9656        302        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.4it/s 2.9s\n",
            "                   all        200       3996      0.654        0.4      0.454      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20         5G      1.217     0.8102     0.9643        145        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.5it/s 1.5s\n",
            "                   all        200       3996      0.521      0.477      0.467      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20         5G        1.2       0.78     0.9552        248        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.9it/s 1.8s\n",
            "                   all        200       3996       0.63      0.388       0.46      0.269\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20         5G      1.255     0.8115     0.9696        148        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 2.9it/s 21.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.8it/s 1.9s\n",
            "                   all        200       3996      0.583      0.447      0.477      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20         5G       1.22     0.7667      0.952         85        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.3it/s 19.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.8it/s 2.5s\n",
            "                   all        200       3996      0.572      0.446      0.457      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20         5G      1.213     0.7533     0.9474        153        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.3it/s 18.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.5it/s 1.6s\n",
            "                   all        200       3996      0.564      0.452      0.466      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      5.04G      1.208     0.7322     0.9481        150        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.5it/s 1.5s\n",
            "                   all        200       3996      0.545      0.438      0.456      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20      5.04G      1.192     0.7196     0.9393        108        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.3it/s 19.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 3.0it/s 2.4s\n",
            "                   all        200       3996      0.657      0.439      0.493      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      5.04G      1.192     0.7111     0.9399        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.3it/s 19.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.5it/s 1.5s\n",
            "                   all        200       3996      0.623      0.444      0.474      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      5.07G      1.169      0.694     0.9309        174        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.2it/s 1.6s\n",
            "                   all        200       3996      0.662      0.413       0.48      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      5.07G      1.169     0.6875     0.9331         98        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.3it/s 19.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.9it/s 2.4s\n",
            "                   all        200       3996      0.561      0.456      0.474      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      5.11G      1.156     0.6747     0.9274        168        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.1it/s 20.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.6it/s 1.5s\n",
            "                   all        200       3996      0.575      0.467      0.481      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      5.11G      1.155     0.6684     0.9253        138        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.2it/s 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 4.6it/s 1.5s\n",
            "                   all        200       3996      0.608      0.467      0.485      0.284\n",
            "\n",
            "20 epochs completed in 0.124 hours.\n",
            "Optimizer stripped from /content/BDD_DomainShift_Lab/yolov8s_day_train/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from /content/BDD_DomainShift_Lab/yolov8s_day_train/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating /content/BDD_DomainShift_Lab/yolov8s_day_train/weights/best.pt...\n",
            "Ultralytics 8.3.236 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,134,098 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 7/7 2.1it/s 3.3s\n",
            "                   all        200       3996      0.609      0.467      0.484      0.284\n",
            "Speed: 0.1ms preprocess, 2.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/BDD_DomainShift_Lab/yolov8s_day_train\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ĞÑ†Ñ–Ğ½ĞºĞ° YOLOv8n (Night)\n",
        "print(\"ĞÑ†Ñ–Ğ½ĞºĞ° YOLOv8n Ğ½Ğ° Ğ½Ñ–Ñ‡Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…\")\n",
        "!yolo task=detect mode=val \\\n",
        "    model='BDD_DomainShift_Lab/yolov8n_day_train/weights/best.pt' \\\n",
        "    data='bdd_domain_shift.yaml' \\\n",
        "    split=test \\\n",
        "    project='BDD_DomainShift_Lab' \\\n",
        "    name='yolov8n_night_test' \\\n",
        "    exist_ok=True\n",
        "\n",
        "# ĞÑ†Ñ–Ğ½ĞºĞ° YOLOv8s (Night)\n",
        "print(\"\\nĞÑ†Ñ–Ğ½ĞºĞ° YOLOv8s Ğ½Ğ° Ğ½Ñ–Ñ‡Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…\")\n",
        "!yolo task=detect mode=val \\\n",
        "    model='BDD_DomainShift_Lab/yolov8s_day_train/weights/best.pt' \\\n",
        "    data='bdd_domain_shift.yaml' \\\n",
        "    split=test \\\n",
        "    project='BDD_DomainShift_Lab' \\\n",
        "    name='yolov8s_night_test' \\\n",
        "    exist_ok=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiSWOdKvnMfg",
        "outputId": "fa9e04cb-604d-48ff-ccd6-169739faeed4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ĞÑ†Ñ–Ğ½ĞºĞ° YOLOv8n Ğ½Ğ° Ğ½Ñ–Ñ‡Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…\n",
            "Ultralytics 8.3.236 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,009,938 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 19.5Â±12.1 MB/s, size: 48.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/bdd100k-finetune-1/test/labels... 60 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 700.7it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/bdd100k-finetune-1/test/labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.0it/s 2.0s\n",
            "                   all         60        881          0          0          0          0\n",
            "                  bike          3          4          0          0          0          0\n",
            "                   bus          4          4          0          0          0          0\n",
            "                   car         60        620          0          0          0          0\n",
            "                person          9         14          0          0          0          0\n",
            "              tl_green         31        103          0          0          0          0\n",
            "               tl_none         11         27          0          0          0          0\n",
            "                tl_red         28         94          0          0          0          0\n",
            "             tl_yellow          3          8          0          0          0          0\n",
            "                 truck          6          7          0          0          0          0\n",
            "Speed: 4.8ms preprocess, 7.0ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/BDD_DomainShift_Lab/yolov8n_night_test\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "\n",
            "ĞÑ†Ñ–Ğ½ĞºĞ° YOLOv8s Ğ½Ğ° Ğ½Ñ–Ñ‡Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…\n",
            "Ultralytics 8.3.236 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,134,098 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2054.5Â±532.5 MB/s, size: 48.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/bdd100k-finetune-1/test/labels.cache... 60 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 60/60 1.1Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.9it/s 2.1s\n",
            "                   all         60        881          0          0          0          0\n",
            "                  bike          3          4          0          0          0          0\n",
            "                   bus          4          4          0          0          0          0\n",
            "                   car         60        620          0          0          0          0\n",
            "                person          9         14          0          0          0          0\n",
            "              tl_green         31        103          0          0          0          0\n",
            "               tl_none         11         27          0          0          0          0\n",
            "                tl_red         28         94          0          0          0          0\n",
            "             tl_yellow          3          8          0          0          0          0\n",
            "                 truck          6          7          0          0          0          0\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/BDD_DomainShift_Lab/yolov8s_night_test\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ĞĞ½Ğ°Ğ»Ñ–Ğ· Ñ‚Ğ° Ğ¿Ğ¾Ñ€Ñ–Ğ²Ğ½ÑĞ»ÑŒĞ½Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ\n",
        "\n",
        "import glob\n",
        "\n",
        "# Ğ¤ÑƒĞ½ĞºÑ†Ñ–Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑˆÑƒĞºÑƒ Ñ„Ğ°Ğ¹Ğ»Ñƒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ²\n",
        "def get_metrics_from_folder(folder_pattern):\n",
        "    # Ğ¨ÑƒĞºĞ°Ñ”Ğ¼Ğ¾ Ğ¿Ğ°Ğ¿ĞºÑƒ\n",
        "    found_folders = glob.glob(folder_pattern)\n",
        "    if not found_folders:\n",
        "        print(f\"ĞŸĞ°Ğ¿ĞºÑƒ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾: {folder_pattern}\")\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    folder = found_folders[0] # Ğ‘ĞµÑ€ĞµĞ¼Ğ¾ Ğ¿ĞµÑ€ÑˆÑƒ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñƒ\n",
        "    csv_path = os.path.join(folder, 'results.csv')\n",
        "\n",
        "    if os.path.exists(csv_path):\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            df.columns = df.columns.str.strip()\n",
        "            # Ğ‘ĞµÑ€ĞµĞ¼Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ½Ğ½Ñ–Ğ¹ Ñ€ÑĞ´Ğ¾Ğº\n",
        "            map50 = df.iloc[-1].get('metrics/mAP50(B)', 0.0)\n",
        "            map5095 = df.iloc[-1].get('metrics/mAP50-95(B)', 0.0)\n",
        "            return map50, map5095\n",
        "        except Exception as e:\n",
        "            print(f\"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ñ‡Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ CSV Ñƒ {folder}: {e}\")\n",
        "            return 0.0, 0.0\n",
        "    else:\n",
        "        print(f\"Ğ¤Ğ°Ğ¹Ğ» results.csv Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–Ğ¹ Ñƒ {folder}\")\n",
        "        # Ğ¯ĞºÑ‰Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ½ĞµĞ¼Ğ°Ñ”, Ğ°Ğ»Ğµ Ğ¿Ğ°Ğ¿ĞºĞ° Ñ”, Ñ– Ğ¼Ğ¸ Ğ±Ğ°Ñ‡Ğ¸Ğ»Ğ¸ Ğ² Ğ»Ğ¾Ğ³Ğ°Ñ… Ğ½ÑƒĞ»Ñ– -> Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ”Ğ¼Ğ¾ 0\n",
        "        return 0.0, 0.0\n",
        "\n",
        "# ĞÑ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ğ¼Ğ¾ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ (Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ°Ğ±Ğ¾ 0)\n",
        "print(\"Ğ—Ñ‡Ğ¸Ñ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº...\")\n",
        "# Ğ¨ÑƒĞºĞ°Ñ”Ğ¼Ğ¾ Ğ¿Ğ°Ğ¿ĞºĞ¸, Ğ½Ğ°Ğ²Ñ–Ñ‚ÑŒ ÑĞºÑ‰Ğ¾ YOLO Ğ´Ğ¾Ğ´Ğ°Ğ² Ñ†Ğ¸Ñ„Ñ€Ñƒ (Ğ½Ğ°Ğ¿Ñ€. night_test2)\n",
        "map50_n, map5095_n = get_metrics_from_folder('BDD_DomainShift_Lab/yolov8n_night_test*')\n",
        "map50_s, map5095_s = get_metrics_from_folder('BDD_DomainShift_Lab/yolov8s_night_test*')\n",
        "\n",
        "print(f\"YOLOv8n Night mAP: {map50_n}\")\n",
        "print(f\"YOLOv8s Night mAP: {map50_s}\")\n",
        "\n",
        "\n",
        "# Ğ¤ÑƒĞ½ĞºÑ†Ñ–Ñ FPS\n",
        "def measure_fps(model_path, device_name=\"cuda\"):\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "        dev = torch.device(device_name)\n",
        "        dummy_input = np.random.rand(640, 640, 3).astype(np.float32)\n",
        "        # ĞŸÑ€Ğ¾Ğ³Ñ€Ñ–Ğ²\n",
        "        for _ in range(5): model.predict(source=dummy_input, device=dev, verbose=False)\n",
        "        # Ğ¢ĞµÑÑ‚\n",
        "        times = []\n",
        "        for _ in range(20): # ĞœĞµĞ½ÑˆĞµ Ñ–Ñ‚ĞµÑ€Ğ°Ñ†Ñ–Ğ¹ Ğ´Ğ»Ñ ÑˆĞ²Ğ¸Ğ´ĞºĞ¾ÑÑ‚Ñ–\n",
        "            if device_name == \"cuda\": torch.cuda.synchronize()\n",
        "            start = time.time()\n",
        "            model.predict(source=dummy_input, device=dev, verbose=False)\n",
        "            if device_name == \"cuda\": torch.cuda.synchronize()\n",
        "            times.append(time.time() - start)\n",
        "        return 1.0 / np.mean(times)\n",
        "    except: return 0.0\n",
        "\n",
        "# Ğ—Ğ±Ñ–Ñ€ Ñ‚ĞµÑ…Ğ½Ñ–Ñ‡Ğ½Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ… Ñ‚Ğ° Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ–\n",
        "# Ğ¨Ğ»ÑÑ…Ğ¸ Ğ´Ğ¾ Ğ²Ğ°Ğ³\n",
        "path_n = 'BDD_DomainShift_Lab/yolov8n_day_train/weights/best.pt'\n",
        "path_s = 'BDD_DomainShift_Lab/yolov8s_day_train/weights/best.pt'\n",
        "\n",
        "try:\n",
        "    # v8n\n",
        "    if os.path.exists(path_n):\n",
        "        model_n = YOLO(path_n)\n",
        "        info_n = summary(model_n.model, input_size=(1, 3, 640, 640), verbose=0)\n",
        "        params_n = info_n.total_params / 1e6\n",
        "        flops_n = info_n.total_mult_adds / 1e9\n",
        "        size_n = os.path.getsize(path_n) / (1024**2)\n",
        "        fps_n_gpu = measure_fps(path_n, \"cuda\")\n",
        "        fps_n_cpu = measure_fps(path_n, \"cpu\")\n",
        "    else:\n",
        "        print(\"Ğ’Ğ°Ğ³Ğ¸ v8n Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾\")\n",
        "        params_n, flops_n, size_n, fps_n_gpu, fps_n_cpu = 0,0,0,0,0\n",
        "\n",
        "    # v8s\n",
        "    if os.path.exists(path_s):\n",
        "        model_s = YOLO(path_s)\n",
        "        info_s = summary(model_s.model, input_size=(1, 3, 640, 640), verbose=0)\n",
        "        params_s = info_s.total_params / 1e6\n",
        "        flops_s = info_s.total_mult_adds / 1e9\n",
        "        size_s = os.path.getsize(path_s) / (1024**2)\n",
        "        fps_s_gpu = measure_fps(path_s, \"cuda\")\n",
        "        fps_s_cpu = measure_fps(path_s, \"cpu\")\n",
        "    else:\n",
        "        print(\"Ğ’Ğ°Ğ³Ğ¸ v8s Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾\")\n",
        "        params_s, flops_s, size_s, fps_s_gpu, fps_s_cpu = 0,0,0,0,0\n",
        "\n",
        "    # Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ\n",
        "    data = {\n",
        "        'imgsz': [640, 640],\n",
        "        'ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸ (M)': [params_n, params_s],\n",
        "        'FLOPs (G)': [flops_n, flops_s],\n",
        "        'mAP@0.5 (Night)': [map50_n, map50_s],\n",
        "        'mAP@0.5:0.95 (Night)': [map5095_n, map5095_s],\n",
        "        'FPS (GPU)': [fps_n_gpu, fps_s_gpu],\n",
        "        'FPS (CPU)': [fps_n_cpu, fps_s_cpu],\n",
        "        'Ğ Ğ¾Ğ·Ğ¼Ñ–Ñ€ Ğ²Ğ°Ğ³ (MB)': [size_n, size_s]\n",
        "    }\n",
        "    df = pd.DataFrame(data, index=['YOLOv8n', 'YOLOv8s'])\n",
        "    df.index.name = \"ĞœĞ¾Ğ´ĞµĞ»ÑŒ\"\n",
        "\n",
        "    print(\"\\nĞ¤Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ (Domain Shift: Day -> Night)\")\n",
        "    pd.options.display.float_format = '{:,.3f}'.format\n",
        "    display(df)\n",
        "\n",
        "    df.to_csv('yolo_comparison.csv')\n",
        "    print(\"\\nĞ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾ Ñƒ Ñ„Ğ°Ğ¹Ğ» 'yolo_comparison.csv'\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ° Ğ¿Ğ¾Ğ¼Ğ¸Ğ»ĞºĞ°: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "HEw-TMqUldxS",
        "outputId": "71218cd2-29ce-4532-ea46-4eed9e17da08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ğ—Ñ‡Ğ¸Ñ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº...\n",
            "Ğ¤Ğ°Ğ¹Ğ» results.csv Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–Ğ¹ Ñƒ BDD_DomainShift_Lab/yolov8n_night_test\n",
            "Ğ¤Ğ°Ğ¹Ğ» results.csv Ğ²Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–Ğ¹ Ñƒ BDD_DomainShift_Lab/yolov8s_night_test\n",
            "YOLOv8n Night mAP: 0.0\n",
            "YOLOv8s Night mAP: 0.0\n",
            "\n",
            "Ğ¤Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ (Domain Shift: Day -> Night)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         imgsz  ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸ (M)  FLOPs (G)  mAP@0.5 (Night)  \\\n",
              "ĞœĞ¾Ğ´ĞµĞ»ÑŒ                                                      \n",
              "YOLOv8n    640          5.064      4.053            0.000   \n",
              "YOLOv8s    640         18.951     14.240            0.000   \n",
              "\n",
              "         mAP@0.5:0.95 (Night)  FPS (GPU)  FPS (CPU)  Ğ Ğ¾Ğ·Ğ¼Ñ–Ñ€ Ğ²Ğ°Ğ³ (MB)  \n",
              "ĞœĞ¾Ğ´ĞµĞ»ÑŒ                                                                \n",
              "YOLOv8n                 0.000     88.086      6.293            5.941  \n",
              "YOLOv8s                 0.000     67.296      2.039           21.464  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8834d49-e93a-4177-9463-7b7fe6739477\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imgsz</th>\n",
              "      <th>ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸ (M)</th>\n",
              "      <th>FLOPs (G)</th>\n",
              "      <th>mAP@0.5 (Night)</th>\n",
              "      <th>mAP@0.5:0.95 (Night)</th>\n",
              "      <th>FPS (GPU)</th>\n",
              "      <th>FPS (CPU)</th>\n",
              "      <th>Ğ Ğ¾Ğ·Ğ¼Ñ–Ñ€ Ğ²Ğ°Ğ³ (MB)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ĞœĞ¾Ğ´ĞµĞ»ÑŒ</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>YOLOv8n</th>\n",
              "      <td>640</td>\n",
              "      <td>5.064</td>\n",
              "      <td>4.053</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>88.086</td>\n",
              "      <td>6.293</td>\n",
              "      <td>5.941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>YOLOv8s</th>\n",
              "      <td>640</td>\n",
              "      <td>18.951</td>\n",
              "      <td>14.240</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>67.296</td>\n",
              "      <td>2.039</td>\n",
              "      <td>21.464</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8834d49-e93a-4177-9463-7b7fe6739477')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8834d49-e93a-4177-9463-7b7fe6739477 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8834d49-e93a-4177-9463-7b7fe6739477');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7fc93f93-6685-4ce8-a0d5-6d5052377068\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fc93f93-6685-4ce8-a0d5-6d5052377068')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7fc93f93-6685-4ce8-a0d5-6d5052377068 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"\\u041c\\u043e\\u0434\\u0435\\u043b\\u044c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"YOLOv8s\",\n          \"YOLOv8n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"imgsz\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 640,\n        \"max\": 640,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          640\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041f\\u0430\\u0440\\u0430\\u043c\\u0435\\u0442\\u0440\\u0438 (M)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.819518331232342,\n        \"min\": 5.064238,\n        \"max\": 18.951134,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          18.951134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLOPs (G)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.2028023935133705,\n        \"min\": 4.053392,\n        \"max\": 14.239692832,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          14.239692832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mAP@0.5 (Night)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mAP@0.5:0.95 (Night)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FPS (GPU)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.70115176582369,\n        \"min\": 67.29573078524447,\n        \"max\": 88.08629899497751,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          67.29573078524447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FPS (CPU)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0081000190590745,\n        \"min\": 2.0389801511599264,\n        \"max\": 6.293075995088035,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0389801511599264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0420\\u043e\\u0437\\u043c\\u0456\\u0440 \\u0432\\u0430\\u0433 (MB)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.976382656592545,\n        \"min\": 5.941019058227539,\n        \"max\": 21.46396827697754,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          21.46396827697754\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾ Ñƒ Ñ„Ğ°Ğ¹Ğ» 'yolo_comparison.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ğ†Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ½Ğ° Ğ²Ğ»Ğ°ÑĞ½Ğ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ…\n",
        "\n",
        "# Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ñ„Ğ°Ğ¹Ğ»Ñ–Ğ²\n",
        "uploaded = files.upload()\n",
        "file_names = list(uploaded.keys())\n",
        "\n",
        "if file_names:\n",
        "    print(f\"Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ¾: {file_names}\")\n",
        "\n",
        "    # Ğ¨Ğ»ÑÑ…Ğ¸ Ğ´Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹\n",
        "    path_n = 'BDD_DomainShift_Lab/yolov8n_day_train/weights/best.pt'\n",
        "    path_s = 'BDD_DomainShift_Lab/yolov8s_day_train/weights/best.pt'\n",
        "\n",
        "    # Ğ†Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ YOLOv8n\n",
        "    print(\"\\nĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· YOLOv8n\")\n",
        "    try:\n",
        "        model_n = YOLO(path_n)\n",
        "        # Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ğ¼Ğ¾ Python API - Ñ†Ğµ Ğ½Ğ°Ğ´Ñ–Ğ¹Ğ½Ñ–ÑˆĞµ Ğ´Ğ»Ñ ÑĞ¿Ğ¸ÑĞºÑ–Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ–Ğ²\n",
        "        results_n = model_n.predict(\n",
        "            source=file_names,\n",
        "            save=True,\n",
        "            conf=0.25,\n",
        "            project='BDD_DomainShift_Lab',\n",
        "            name='infer_v8n',\n",
        "            exist_ok=True\n",
        "        )\n",
        "        print(\"YOLOv8n: Ğ£ÑĞ¿Ñ–ÑˆĞ½Ğ¾!\")\n",
        "    except Exception as e:\n",
        "        print(f\"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° v8n: {e}\")\n",
        "\n",
        "    # Ğ†Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ YOLOv8s\n",
        "    print(\"\\nĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· YOLOv8s\")\n",
        "    try:\n",
        "        model_s = YOLO(path_s)\n",
        "        results_s = model_s.predict(\n",
        "            source=file_names,\n",
        "            save=True,\n",
        "            conf=0.25,\n",
        "            project='BDD_DomainShift_Lab',\n",
        "            name='infer_v8s',\n",
        "            exist_ok=True\n",
        "        )\n",
        "        print(\"YOLOv8s: Ğ£ÑĞ¿Ñ–ÑˆĞ½Ğ¾!\")\n",
        "    except Exception as e:\n",
        "        print(f\"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° v8s: {e}\")\n",
        "\n",
        "    print(\"\\nĞ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸ Ñ–Ğ½Ñ„ĞµÑ€ĞµĞ½ÑÑƒ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾ Ñƒ Ğ¿Ğ°Ğ¿ĞºĞ°Ñ…:\")\n",
        "    print(\"- BDD_DomainShift_Lab/infer_v8n\")\n",
        "    print(\"- BDD_DomainShift_Lab/infer_v8s\")\n",
        "\n",
        "    # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ Ğ°Ñ€Ñ…Ñ–Ğ²Ñƒ Ğ´Ğ»Ñ Ğ·Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ\n",
        "    print(\"\\nĞ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ Ğ°Ñ€Ñ…Ñ–Ğ²Ñƒ Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸...\")\n",
        "    !zip -r my_inference_results.zip BDD_DomainShift_Lab/infer_v8n BDD_DomainShift_Lab/infer_v8s\n",
        "    print(\"ĞÑ€Ñ…Ñ–Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾: my_inference_results.zip\")\n",
        "\n",
        "else:\n",
        "    print(\"Ğ¤Ğ°Ğ¹Ğ»Ğ¸ Ğ½Ğµ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ¾. Ğ†Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "ltLmAT2DkIQy",
        "outputId": "020f4b6e-69bf-4f65-bf7c-b7c911ab8d03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cace3440-70d6-4f5e-836d-b4ecd0c42204\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cace3440-70d6-4f5e-836d-b4ecd0c42204\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving day_1.jpg to day_1.jpg\n",
            "Saving day_2.jpg to day_2.jpg\n",
            "Saving night_1.jpeg to night_1.jpeg\n",
            "Saving night_2.jpg to night_2.jpg\n",
            "Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ¾: ['day_1.jpg', 'day_2.jpg', 'night_1.jpeg', 'night_2.jpg']\n",
            "\n",
            "ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· YOLOv8n\n",
            "\n",
            "0: 640x640 7 10s, 4 5s, 1 6, 16.7ms\n",
            "1: 640x640 14 10s, 8 5s, 2 6s, 16.7ms\n",
            "2: 640x640 5 10s, 16.7ms\n",
            "3: 640x640 4 10s, 1 5, 1 6, 16.7ms\n",
            "Speed: 4.5ms preprocess, 16.7ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/BDD_DomainShift_Lab/infer_v8n\u001b[0m\n",
            "YOLOv8n: Ğ£ÑĞ¿Ñ–ÑˆĞ½Ğ¾!\n",
            "\n",
            "ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· YOLOv8s\n",
            "\n",
            "0: 640x640 6 10s, 6 5s, 1 6, 15.1ms\n",
            "1: 640x640 9 10s, 8 5s, 2 6s, 15.1ms\n",
            "2: 640x640 3 10s, 15.1ms\n",
            "3: 640x640 1 1, 5 10s, 2 5s, 15.1ms\n",
            "Speed: 3.3ms preprocess, 15.1ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/BDD_DomainShift_Lab/infer_v8s\u001b[0m\n",
            "YOLOv8s: Ğ£ÑĞ¿Ñ–ÑˆĞ½Ğ¾!\n",
            "\n",
            "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸ Ñ–Ğ½Ñ„ĞµÑ€ĞµĞ½ÑÑƒ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾ Ñƒ Ğ¿Ğ°Ğ¿ĞºĞ°Ñ…:\n",
            "- BDD_DomainShift_Lab/infer_v8n\n",
            "- BDD_DomainShift_Lab/infer_v8s\n",
            "\n",
            "Ğ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ Ğ°Ñ€Ñ…Ñ–Ğ²Ñƒ Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸...\n",
            "  adding: BDD_DomainShift_Lab/infer_v8n/ (stored 0%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8n/night_1.jpg (deflated 4%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8n/night_2.jpg (deflated 2%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8n/day_1.jpg (deflated 0%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8n/day_2.jpg (deflated 6%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8s/ (stored 0%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8s/night_1.jpg (deflated 4%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8s/night_2.jpg (deflated 2%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8s/day_1.jpg (deflated 0%)\n",
            "  adding: BDD_DomainShift_Lab/infer_v8s/day_2.jpg (deflated 6%)\n",
            "ĞÑ€Ñ…Ñ–Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾: my_inference_results.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s9QShvOfqOB5"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}