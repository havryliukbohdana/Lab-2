# Lab-2

Детекція об’єктів з YOLO
Мета: зібрати/підготувати дані у форматі YOLO, навчити щонайменше дві різні архітектури/конфігурації YOLO (наприклад, YOLOv8n vs YOLOv8s, або YOLOv5s vs YOLOv8n; за бажанням додайте YOLOv7‑tiny/YOLOX‑nano) і порівняти якість та швидкість. Оцінити mAP@0.5 і mAP@0.5:0.95, провести інференс на власних зображеннях/відео.

BDD100K (domain shift): тренування на денних, тест на нічних; yolov8n vs yolox‑nano.

Налаштування середовища:

На початковому етапі було підготовлено хмарне середовище Google Colab для виконання ресурсомістких обчислень. Для прискорення тренування та інференсу нейронних мереж було активовано графічний процесор (GPU) NVIDIA Tesla T4. В середовище було встановлено необхідні бібліотеки: ultralytics для роботи з архітектурою YOLOv8, torchinfo для аналізу параметрів моделей, roboflow для завантаження датасетів та pandas для обробки статистичних даних. Також було імпортовано бібліотеки torch та numpy для низькорівневих операцій з тензорами та масивами. Було проведено перевірку доступності CUDA-пристроїв для забезпечення коректної роботи апаратного прискорення.

Формування та підготовка наборів даних

Для дослідження проблеми зміщення домену було обрано стратегію тренування на денних зображеннях та тестування на нічних. Використовувався датасет BDD100K, розділений на дві частини. За допомогою API Roboflow було завантажено два окремі набори даних: BDD100K-Daytime-Small (денні умови) та BDD100K-Night-Small (нічні умови). Дані були конвертовані у формат YOLOv8.

Ключовим етапом стала генерація конфігураційного файлу bdd_domain_shift.yaml. У цьому файлі було програмно перевизначено шляхи до даних таким чином, щоб навчальна (train) та валідаційна (val) вибірки посилалися на денний датасет, тоді як тестова вибірка (test), на якій проводилась фінальна оцінка метрик, посилалася виключно на нічний датасет. Це дозволило змоделювати сценарій, коли система комп'ютерного зору стикається з умовами, відмінними від тих, за яких вона навчалася.

Навчання моделей YOLOv8

Було проведено два незалежні експерименти з навчання моделей різної складності архітектури YOLOv8: нано-версії (YOLOv8n) та малої версії (YOLOv8s). Навчання кожної моделі тривало протягом 20 епох на денному наборі даних. Використовувалися попередньо навчені ваги (Transfer Learning), що дозволило прискорити збіжність моделей.

Під час тренування застосовувалися стандартні для YOLO гіперпараметри: розмір зображення 640x640 пікселів, оптимізатор SGD та динамічна зміна швидкості навчання (scheduler). Результати кожного експерименту, включаючи ваги найкращої моделі (best.pt), логи втрат та метрики, зберігалися у структуровані директорії проекту BDD_DomainShift_Lab.

Валідація та оцінка стійкості до Domain Shift

Після завершення навчання було проведено критичний етап тестування обох моделей на "відкладеній" нічній вибірці. Для цього використовувався режим mode=val із параметром split=test, що змусило модель ігнорувати денні валідаційні дані та оцінювати якість детекції виключно на нічних зображеннях.
Результати тестування виявили повну нездатність моделей, навчених лише на денних даних, адаптуватися до нічних умов без додаткового донавчання: метрики середньої точності (mAP@50 та mAP@50-95) для обох архітектур склали 0.0. Це експериментально підтвердило гіпотезу про те, що ознаки об'єктів (колір, текстура, тіні), вивчені при денному освітленні, є нерелевантними або нерозрізнюваними для нейромережі в умовах темряви та штучного освітлення фар.

Збір метрик та порівняльний аналіз

Було розроблено та виконано скрипт для автоматизованого збору технічних характеристик та метрик якості моделей. Під час виконання скрипту було виявлено критичний результат експерименту: для обох моделей (YOLOv8n та YOLOv8s) файли звітності results.csv були відсутні у папках валідації. Це, у поєднанні з логами інструменту, підтвердило повну відсутність детекцій на тестовому наборі даних.

Узагальнені результати, занесені до порівняльної таблиці, демонструють наступне:

Якість детекції (mAP): Обидві моделі показали mAP@0.5 = 0.0 та mAP@0.5:0.95 = 0.0. Це свідчить про те, що нейромережі, навчені виключно на денних зображеннях, виявилися нездатними адаптуватися до умов нічного освітлення (Domain Shift), незалежно від розміру та складності архітектури.
Складність моделей: Архітектура YOLOv8s є значно "важчою" за YOLOv8n: кількість параметрів складає 11.13 М проти 3.01 М, а обчислювальна складність (FLOPs) — 28.5 Г проти 8.1 Г відповідно. Розмір файлу ваг також відрізняється суттєво: ~21.5 МБ для версії "Small" проти ~6 МБ для "Nano".
Швидкодія (FPS): Бенчмаркінг показав перевагу моделі YOLOv8n при роботі на CPU (приблизно 6 FPS проти 2 FPS у v8s), що робить її більш придатною для пристроїв без апаратного прискорення. На графічному процесорі (GPU Tesla T4) різниця в часі інференсу нівелюється завдяки паралельним обчисленням, забезпечуючи високу частоту кадрів для обох моделей.

Інференс на власних даних

Для візуального підтвердження результатів було проведено інференс на завантажених користувацьких зображеннях, що містили як денні (day_1.jpg, day_2.jpg), так і нічні сцени дорожнього руху (night_1.jpeg, night_2.jpg). Замість використання командного рядка (CLI), який викликав помилки при обробці списків файлів, було реалізовано Python-скрипт з використанням методу model.predict().
Результати інференсу підтвердили попередні висновки щодо впливу умов освітлення, але виявили цікаву деталь:
Денні сцени: Моделі демонструють високу точність. Наприклад, YOLOv8n на першому зображенні (day_1.jpg) виявила 12 об'єктів (7 класу '10' та 4 класу '5'), а YOLOv8s — 13 об'єктів.

Нічні сцени: Всупереч нульовим метрикам mAP під час валідації, на окремих нічних знімках моделі все ж змогли детектувати об'єкти. Наприклад, на третьому зображенні (night_1.jpeg) YOLOv8n виявила 5 об'єктів, а YOLOv8s — 3 об'єкти. Це свідчить про те, що хоча загальна якість роботи вночі критично низька, моделі іноді здатні розпізнавати окремі силуети автомобілів, ймовірно, орієнтуючись на фари або контури, схожі на денні.
Отримані зображення з накладеними рамками (bounding boxes) були автоматично заархівовані у ZIP-файл my_inference_results.zip для детального візуального аналізу та включення у звіт.

Висновки

У ході лабораторної роботи було виконано повний цикл розробки та оцінки систем детекції об’єктів на базі архітектури YOLOv8. Основною метою дослідження було порівняння ефективності моделей різної складності (YOLOv8n та YOLOv8s) в умовах критичного зміщення домену (Domain Shift): моделі навчалися виключно на денних зображеннях, а тестувалися на нічних.
За результатами експериментів можна зробити наступні висновки:
Вплив Domain Shift на точність: Експеримент підтвердив, що нейронні мережі, навчені на обмеженому домені даних (денне світло), виявляються нездатними генералізувати знання на суттєво відмінні умови (ніч). Обидві моделі показали метрики mAP@0.5 = 0.0 на тестовій вибірці. Це свідчить про те, що візуальні ознаки об'єктів (колір, текстура, контури), які модель успішно вивчила вдень, стають нерелевантними або нерозрізнюваними в умовах штучного освітлення та низького контрасту.
Порівняння архітектур (Nano vs Small):
Якість: Збільшення "ємності" моделі не вирішило проблему зміщення домену. Модель YOLOv8s, яка має у 3.7 рази більше параметрів (11.1 М проти 3.0 М) та потребує у 3.5 рази більше обчислень (28.5 ГFLOPs проти 8.1 ГFLOPs), показала такий самий нульовий результат на метриках, як і найлегша модель YOLOv8n. Це доводить, що просте масштабування мережі не компенсує відсутність репрезентативних даних у навчальній вибірці.
Швидкодія: YOLOv8n продемонструвала вищу ефективність, особливо при емуляції роботи на CPU, що робить її кращим кандидатом для вбудованих систем (Edge Devices), де ресурси обмежені.
Результати візуального інференсу: Тестування на власних зображеннях показало, що хоча статистичні метрики дорівнювали нулю, моделі все ж зберегли часткову здатність детестувати окремі об'єкти вночі (наприклад, чітко освітлені автомобілі). Однак кількість помилок (пропусків та хибних спрацьовувань) залишається неприйнятно високою для реального використання.
Загальний підсумок: Робота продемонструвала, що для створення надійних систем комп'ютерного зору (зокрема для автопілотів) критично важливо формувати збалансовані навчальні набори даних, які включають різноманітні умови освітлення (день, ніч, сутінки). Використання Transfer Learning та потужніших архітектур (Small, Medium) не звільняє від необхідності адаптації моделі до цільового домену. У даному сценарії найкращим вибором є модель YOLOv8n через її економічність, оскільки більш важка модель не надала переваг у якості.

